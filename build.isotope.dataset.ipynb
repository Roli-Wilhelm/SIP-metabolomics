{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up New Conda Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda create -n metabolomics\n",
    "conda install -c r rpy2 r-essentials r-igraph\n",
    "conda install -y -c conda-forge jupyter_contrib_nbextensions\n",
    "conda install -c conda-forge cycler matplotlib biopython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project/projectdirs/metatlas/mysql_user.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7bacb33a5b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmetatlas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdill2plots\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m '''from metatlas.helpers import metatlas_get_data_helper_fun as ma_data\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetatlas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchromatograms_mp_plots\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metabolomics/lib/python3.6/site-packages/metatlas/helpers/dill2plots.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmetatlas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetatlas_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetatlas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5_query\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetatlas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetatlas_get_data_helper_fun\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mma_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metabolomics/lib/python3.6/site-packages/metatlas/metatlas_objects.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;31m# Must be instantiated after all of the Metatlas Objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;31m# are defined so we can get all of the subclasses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m \u001b[0mworkspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metabolomics/lib/python3.6/site-packages/metatlas/object_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mnersc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnersc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'db_passwd_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mpw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mysql+pymysql://meta_atlas_admin:%s@nerscdb04.nersc.gov/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnersc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'db_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project/projectdirs/metatlas/mysql_user.txt'"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import sys, os\n",
    "#sys.path.insert(0,'/global/homes/b/bpb/repos/metatlas')\n",
    "sys.path.insert(0, '/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages')\n",
    "\n",
    "from metatlas.helpers import dill2plots as dp\n",
    "'''from metatlas.helpers import metatlas_get_data_helper_fun as ma_data\n",
    "from metatlas.helpers import chromatograms_mp_plots as cp\n",
    "from metatlas.helpers import chromplotplus as cpp\n",
    "import metatlas.metatlas_objects as metob\n",
    "from metatlas.helpers import mzmine_helpers as mzm\n",
    "\n",
    "import qgrid\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "import dill\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "# group_names_to_remove = pd.read_csv('/global/homes/b/bpb/Downloads/pks_files_to_remove.csv')['group'].tolist()\n",
    "# And the groups are:\n",
    "# 20180104_NEG or POS_12C or 13C \n",
    "groups = dp.select_groups_for_analysis(name = '20180104_%_1%C',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,\n",
    "                                       include_list = [], exclude_list = ['NEG'])#['QC','Blank'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for g in groups:\n",
    "    for f in g.items:\n",
    "        print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 20180131_TS_DB_fullcyc_12C_refined_POS\n",
    "# 20180131_TS_DB_fullcyc_12C_refined_NEG\n",
    "\n",
    "my_atlas = metob.retrieve('Atlas',name='20180131_TS_DB_fullcyc_12C_refined_POS',username='*')[-1]\n",
    "my_atlas.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatlas.helpers import spectralprocessing as spec\n",
    "new_compound_ids = []\n",
    "for cid in my_atlas.compound_identifications:\n",
    "    k,v = spec.parse_formula(cid.compound[0].formula)\n",
    "    formula = dict(zip(k,v))\n",
    "    for i in range(1,formula['C']+1):\n",
    "        temp_mz = cid.mz_references[0].clone()\n",
    "        temp_mz.mz = cid.mz_references[0].mz + (1.003355 * i)\n",
    "        new_cid = cid.clone()\n",
    "        new_cid.mz_references[0] = temp_mz\n",
    "        new_compound_ids.append(new_cid)\n",
    "my_atlas.compound_identifications.extend(new_compound_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_df = ma_data.make_atlas_df(my_atlas)\n",
    "atlas_df['label'] = [cid.name for cid in my_atlas.compound_identifications]\n",
    "print my_atlas.name\n",
    "print my_atlas.username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(atlas_df.shape)\n",
    "atlas_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much faster data getting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for my_group in groups:\n",
    "    for my_file in my_group.items:\n",
    "        all_files.append((my_file,my_group,atlas_df,my_atlas))\n",
    "        \n",
    "pool = mp.Pool(processes=min(32, len(all_files)))\n",
    "# from metatlas.helpers.metatlas_get_data_helper_fun import get_data_for_atlas_df_and_file\n",
    "t0 = time.time()\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "#If you're code crashes here, make sure to terminate any processes left open.\n",
    "print time.time() - t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "%matplotlib notebook\n",
    "a = dp.adjust_rt_for_selected_compound(metatlas_dataset,compound_idx=0,include_lcmsruns = [],alpha=0.75,width=10,height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/global/homes/b/bpb/Downloads/isotope_tests_pos_v2/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Export Atlas to a Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_identifications = dp.export_atlas_to_spreadsheet(my_atlas,os.path.join(output_dir,'atlas_export.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Dataframes and spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "ma_data = reload(ma_data)\n",
    "peak_height = dp.make_output_dataframe(input_fname = '',input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_height' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "peak_area = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_area' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "mz_peak = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_peak' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "rt_peak = dp.make_output_dataframe(input_fname = my_file, input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [],fieldname='rt_peak' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "mz_centroid = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_centroid' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "rt_centroid = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='rt_centroid' , output_loc=os.path.join(output_dir,'sheets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_isotopic_data(metatlas_dataset):\n",
    "    \"\"\"\n",
    "    takes in a metabolite atlas dataset and returns\n",
    "    a dictionary where the first keys are unique files\n",
    "    and the second layer of keys are the unique compound\n",
    "    names\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a simplified representation of the names that is the \n",
    "    # <name>_<retention time>\n",
    "    compound_names = ['%s_%s'%(s.split('_')[1],s.split('_')[-1]) for s in ma_data.get_compound_names(metatlas_dataset)[0]]\n",
    "    # unique_compound_names = pd.unique(compound_names)\n",
    "    file_names = ma_data.get_file_names(metatlas_dataset)\n",
    "\n",
    "    # initialize an empty dict of lists\n",
    "    # first dimension is number of files\n",
    "    # second dimension is number of compounds\n",
    "    df = {}\n",
    "    for i,d1 in enumerate(metatlas_dataset): #iterate through files\n",
    "        df[file_names[i]] = {}\n",
    "        for j,d2 in enumerate(d1): #iterate through compounds\n",
    "            # for each unique compound and file initialize an empty list\n",
    "            df[file_names[i]][compound_names[j]] = {'data':[],'rt_reference':None}\n",
    "\n",
    "    for i,d1 in enumerate(metatlas_dataset): #iterate through files\n",
    "        for j,d2 in enumerate(d1): #iterate through compounds\n",
    "            # for each unique compound and file append the eic datasets\n",
    "            df[file_names[i]][compound_names[j]]['data'].append(metatlas_dataset[i][j]['data']['eic'])\n",
    "            df[file_names[i]][compound_names[j]]['rt_reference'] = metatlas_dataset[i][j]['identification'].rt_references[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "isotope_data = organize_isotopic_data(metatlas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = isotope_data.keys()[0]\n",
    "c = isotope_data[f].keys()[0]\n",
    "# isotope_data[f][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = isotope_data.keys()\n",
    "compounds = isotope_data[files[0]].keys()\n",
    "unique_compounds = pd.unique(compounds)\n",
    "def plot_isotope_eics(isotope_data,my_file,my_compound,first_file_piece=0,last_file_piece=-1,ax=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    for d in isotope_data[my_file][my_compound]['data']:\n",
    "        try:\n",
    "            ax.semilogy(d['rt'],d['intensity'],'-',label='%.4f'%d['mz'][0])\n",
    "        except:\n",
    "            #no data\n",
    "            pass\n",
    "    rt_info = isotope_data[my_file][my_compound]['rt_reference']\n",
    "    ax.axvline(rt_info.rt_min,color='black',linewidth=6,alpha=0.5)\n",
    "    ax.axvline(rt_info.rt_max,color='black',linewidth=6,alpha=0.5)\n",
    "    ax.axvline(rt_info.rt_peak,color='red',linewidth=6,alpha=0.5)\n",
    "    shortened_filename = '_'.join(my_file.split('_')[first_file_piece:last_file_piece])\n",
    "    ax.set_title('%s\\n%s'%(shortened_filename,my_compound))\n",
    "    ax.set_xlabel('Time (min)')\n",
    "    ax.set_ylabel('Intensity (au)\\nLog Scale')\n",
    "    ax.legend()\n",
    "    \n",
    "plt.ioff()\n",
    "\n",
    "output_dir = '/global/homes/b/bpb/Downloads/isotope_tests_pos_v2/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "alphabet_idx = np.argsort(['_'.join(f.split('_')[7:10]) for f in files])\n",
    "\n",
    "for cpd in unique_compounds:\n",
    "    output_filename = os.path.join(output_dir,'%s.pdf'%cpd)\n",
    "    print(output_filename)\n",
    "#     if not os.path.isfile(output_filename):\n",
    "    fig, all_axes = plt.subplots(8, 14, sharey=True, figsize=(80,40))\n",
    "    all_axes = all_axes.reshape(-1)\n",
    "    for plot_idx,file_idx in enumerate(alphabet_idx):\n",
    "        plot_isotope_eics(isotope_data,files[file_idx],cpd,first_file_piece=6,last_file_piece=10,ax=all_axes[plot_idx])\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(output_dir,'%s.pdf'%cpd))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(isotopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_isotope_pattern_dataframe(peak_height,rt_peak):\n",
    "    df = peak_height.copy()\n",
    "    rt_df = rt_peak.copy()\n",
    "    rt_df.reset_index(inplace=True,drop=True)\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    rt_df.columns = rt_df.columns.droplevel(0)\n",
    "    df.fillna(0,inplace=True)\n",
    "    groups = df.columns.unique()\n",
    "    for i,row in df.iterrows():\n",
    "        df.loc[i,'mz'] = i.split('_')[-2]\n",
    "        df.loc[i,'name'] = i.split('_')[1]\n",
    "        df.loc[i,'rt'] = i.split('_')[-1]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    unique_cpds = df.apply(lambda x: '%s_%s'%(x['name'],x['rt']),axis=1).unique()\n",
    "    small_dataframes = []\n",
    "    for cpd in unique_cpds:\n",
    "        name,rt = cpd.split('_')\n",
    "        idx = (df['name'] == name) & (df['rt'] == rt)\n",
    "        small_df = df[idx].copy()\n",
    "        small_df.drop(['name','rt'],axis=1,inplace=True)\n",
    "        small_df.set_index(['mz'],inplace=True)\n",
    "        small_dataframes.append({'compound':cpd,'peak_height':small_df,'rt_peak':rt_df[idx]})\n",
    "    return small_dataframes\n",
    "isotopes = make_isotope_pattern_dataframe(peak_height,rt_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/global/homes/b/bpb/Downloads/positive_mode_isotope_data.pkl','w') as fid:\n",
    "    pickle.dump(isotopes, fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "mol = Chem.MolFromInchi(str(atlas_df.loc[0,'inchi']))\n",
    "Chem.rdMolDescriptors.CalcMolFormula(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_df.head(61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotopes[29]['peak_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(isotopes)\n",
    "\n",
    "# cpd = 30\n",
    "# print(isotopes[cpd]['compound'])\n",
    "\n",
    "# atlas_df.loc[cpd,:]\n",
    "\n",
    "# [c.split('_')[7:11] for c in isotopes[cpd]['peak_height'].columns]\n",
    "\n",
    "# isotopes[cpd]['peak_height'][c].values\n",
    "# %matplotlib notebook\n",
    "# cpd = 34\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# for c in isotopes[cpd]['peak_height'].columns:\n",
    "#     if 'Cel' in c:\n",
    "#         print(c,c.split('_')[9])\n",
    "#         x = [float(p.replace('p','.')) for p in isotopes[cpd]['peak_height'][c].index]\n",
    "#         y = isotopes[cpd]['peak_height'][c].values\n",
    "#         plt.plot(x,y,label=c.split('_')[9])\n",
    "#         plt.title(isotopes[cpd]['compound'])\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "\n",
    "# cpd = 34\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# for c in isotopes[cpd]['rt_peak'].columns:\n",
    "#     if 'Cel' in c:\n",
    "#         print(c,c.split('_')[9])\n",
    "#         x = [float(p) for p in isotopes[cpd]['rt_peak'][c].index]\n",
    "#         y = isotopes[cpd]['rt_peak'][c].values\n",
    "#         plt.plot(x,y,'o')#,label=c.split('_')[9])\n",
    "#         plt.title(isotopes[cpd]['compound'])\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "\n",
    "# isotopes[cpd]['peak_height'][c for c in isotopes[cpd]['peak_height'].columns if '13C_Cel' in c]\n",
    "\n",
    "# isotopes[cpd]['rt_peak']\n",
    "\n",
    "formula = my_atlas.compound_identifications[cpd].compound[0].formula\n",
    "resolution = 0.3\n",
    "nat_elements, nat_counts = spec.parse_formula(formula)\n",
    "nat_isotope_matrix = spec.make_isotope_matrix(nat_elements)#, isotope_dict=element_dict)\n",
    "nat_dist = spec.make_isotope_distribution(nat_counts, resolution=resolution, *nat_isotope_matrix)[0]\n",
    "nat_dist[1]*590000\n",
    "\n",
    "# #TODO: function that takes in a run and a compound and makes nice looking spectra and chroamtograms for each isotopologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = peak_height.copy()\n",
    "# df.columns = df.columns.droplevel(1)\n",
    "# #filter numbers less than threshold with zero\n",
    "# df.fillna(0,inplace=True)\n",
    "# #only do calculation for non-zero values\n",
    "# df_stats = df.transpose().groupby('group').mean().transpose()\n",
    "# # df_stats = df.transpose().groupby('group').std().transpose()\n",
    "# # df_stats = df.transpose().groupby('group').count().transpose()\n",
    "\n",
    "# df_stats.reset_index(drop=True,inplace=True)\n",
    "# df_stats['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "# df_stats.to_csv('stats.csv')\n",
    "\n",
    "# df_stats = df.transpose().groupby('group').mean().transpose()\n",
    "# df_stats.reset_index(drop=True,inplace=True)\n",
    "# df_stats['fold_change'] = np.log2(np.divide(df_stats[groups[1]],df_stats[groups[0]]))\n",
    "# # print df_stats[df_stats.fold_change>-2].index.tolist()\n",
    "# from scipy.stats import ttest_ind\n",
    "\n",
    "# cat1 = df[[c for c in df.columns if c == groups[0]]]\n",
    "# cat2 = df[[c for c in df.columns if c == groups[1]]]\n",
    "\n",
    "\n",
    "# df_stats['t-score'],df_stats['p-value'] = ttest_ind(cat1,cat2,axis=1)\n",
    "# df_stats['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "\n",
    "# df_stats.to_csv('/global/homes/b/bpb/Downloads/magi_coelicolor_stats.csv')\n",
    "\n",
    "# print(df_stats[df_stats.fold_change<-1].index.tolist())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_metabolomics)",
   "language": "python",
   "name": "conda_metabolomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
